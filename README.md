# Trustpilotscraper-Transformer 500.000 Comments scraped in 2 Days in an analyzable format

The method consists of 2 steps. 1. The Data-Scraping-Process and 2. the CSV. Transformation process with Python. Both steps I will try to explain in detail. 
I'm new to Github, this is my very first post/project/tutorial. If anything is not right, don't be afraid to point it out to me, preferably with a solution.

Webscraper.io Use:
- This is a functional data web scraper method for ANY Trustpilot.com feedback/reputation site. It collects all comments and transfers them to a CSV. text document. It took me about 2 days to get 500,000 comments. Admittedly, this is a very manual method. But the main thing is that this method works and works great. 

Python Use:
- The Python script allows conversion of some rows that are in the wrong data format, such as the date, which is a str and therefore not suitable for Data Science. It also combines the comments into one document so that all the individual scraping pages are contained in one document. 
- In addition, I'll add a couple of Python script tools that allow you to add different dates to the scraped documents, as well as functions that allow you to group the comments by year, so you can get rating averages per year.

# Step 1: Trust-Pilot Data-Scraping Process - Tutorial
1. Install the webscraper.io Addon to your browser. Go to https://webscraper.io/ click on install.
3. Go to your Browser (e.g. Firefox or Chrome) in which you installed the Addon and press CTRL+I+SHIFT, or do a Right Click on your Browser and select Inspect. For more Information see https://developer.chrome.com/docs/devtools/open/ (Same Function in Firefox).
4. Gehe zum Reiter Webscraper.io
5. Importiere eine neue Sitemap. Klicke dazu auf "Create new Sitemap" und w√§hle "Import Sitemap" aus. Kopiere nun den Gesamten Inhalt aus dem im Github-Projekt abgelegtem Dokument "Sitemap_Trustpilot.com" in den 
7. 

# Auszug aus meiner Masterarbeit
Translated with deepL.com

# Bugs that happend to me:
-No Scraping function on Windows 10 Chrome browser. Try Firefox in this case. 
